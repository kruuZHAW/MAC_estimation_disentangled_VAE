{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_traffic_generation.tcvae import TCVAE\n",
    "from deep_traffic_generation.core.datasets import TrafficDataset\n",
    "from traffic.core import Traffic\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = TrafficDataset.from_file(\n",
    "    (\"../deep_traffic_generation/data/training_datasets/takeoffs_south_LFPO_07.pkl\"),\n",
    "    features=[\"track\", \"groundspeed\", \"altitude\", \"timedelta\"],\n",
    "    scaler=MinMaxScaler(feature_range=(-1,1)),\n",
    "    # scaler=None,\n",
    "    shape=\"image\",\n",
    "    info_params={\"features\": [\"latitude\", \"longitude\"], \"index\": -1},\n",
    ")\n",
    "\n",
    "dataset2 = TrafficDataset.from_file(\n",
    "    (\"../deep_traffic_generation/data/training_datasets/landings_south_LFPO_06.pkl\"),\n",
    "    features=[\"track\", \"groundspeed\", \"altitude\", \"timedelta\"],\n",
    "    scaler=MinMaxScaler(feature_range=(-1,1)),\n",
    "    # scaler=None,\n",
    "    shape=\"image\",\n",
    "    info_params={\"features\": [\"latitude\", \"longitude\"], \"index\": -1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic1 = Traffic.from_file(\"../deep_traffic_generation/data/training_datasets/takeoffs_south_LFPO_07.pkl\")\n",
    "traffic2 = Traffic.from_file(\"../deep_traffic_generation/data/training_datasets/landings_south_LFPO_06.pkl\")\n",
    "\n",
    "data1 = np.stack(\n",
    "    list([f.flight_id, f.start, f.stop] for f in traffic1)\n",
    ")\n",
    "data2 = np.stack(\n",
    "    list([f.flight_id, f.start, f.stop] for f in traffic2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairs(iter):\n",
    "    x, y = iter\n",
    "    delta_t = y[1] - x[1]\n",
    "    len_x = x[2] - x[1]\n",
    "    len_y = y[2] - y[1]\n",
    "\n",
    "    #modified according to sandobox_tcas\n",
    "    if delta_t < -len_y or (delta_t > len_x):\n",
    "        return\n",
    "    \n",
    "    #make sure that delta_t is smaller than the total duration of the reference (the takeoff)\n",
    "    elif (delta_t < len_x): \n",
    "        return np.array([x[0], y[0], delta_t.total_seconds()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os\n",
    "import itertools\n",
    "with Pool(processes=os.cpu_count()) as p: \n",
    "    pairs = p.map(calculate_pairs, itertools.product(data1,data2))\n",
    "    p.close()\n",
    "    p.join()\n",
    "pairs = np.stack([x for x in pairs if x is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "for i in range(len(pairs)):\n",
    "    a.append(dataset1.get_flight(pairs[i,0]))\n",
    "    b.append(dataset2.get_flight(pairs[i,1]))\n",
    "    \n",
    "a = torch.stack(a)\n",
    "b = torch.stack(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): TCN(\n",
       "      (network): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (tmp_block1): TemporalBlock(\n",
       "            (conv): Conv1d(4, 64, kernel_size=(16,), stride=(1,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (tmp_block2): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (downsample): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (tmp_block1): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (tmp_block2): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (tmp_block1): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (tmp_block2): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AvgPool1d(kernel_size=(10,), stride=(10,), padding=(0,))\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (lsr): VampPriorLSR(\n",
       "    (encoder): Sequential(\n",
       "      (0): TCN(\n",
       "        (network): Sequential(\n",
       "          (0): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(4, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (downsample): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): AvgPool1d(kernel_size=(10,), stride=(10,), padding=(0,))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (z_loc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=True)\n",
       "    )\n",
       "    (z_log_var): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=True)\n",
       "      (1): Hardtanh(min_val=-6.0, max_val=6.0)\n",
       "    )\n",
       "    (pseudo_inputs_NN): Sequential(\n",
       "      (0): Linear(in_features=800, out_features=800, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=800, out_features=800, bias=True)\n",
       "      (3): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (prior_log_var_NN): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=True)\n",
       "      (1): Hardtanh(min_val=-6.0, max_val=6.0)\n",
       "    )\n",
       "  )\n",
       "  (decoder): TCDecoder(\n",
       "    (decode_entry): Linear(in_features=64, out_features=1280, bias=True)\n",
       "    (decoder): Sequential(\n",
       "      (0): Upsample(scale_factor=10.0, mode=nearest)\n",
       "      (1): TCN(\n",
       "        (network): Sequential(\n",
       "          (0): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 4, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(4, 4, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (downsample): Conv1d(64, 4, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_activ): Identity()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames1 = next(walk(\"../deep_traffic_generation/lightning_logs/tcvae/version_0/\"+ \"checkpoints/\"), (None, None, []))[2]\n",
    "VAE1 = TCVAE.load_from_checkpoint(\n",
    "    \"../deep_traffic_generation/lightning_logs/tcvae/version_0/\" + \"checkpoints/\" + filenames1[0],\n",
    "    dataset_params=dataset1.parameters,\n",
    ")\n",
    "VAE1.eval()\n",
    "\n",
    "filenames2 = next(walk(\"../deep_traffic_generation/lightning_logs/tcvae/version_1/\"+ \"checkpoints/\"), (None, None, []))[2]\n",
    "VAE2 = TCVAE.load_from_checkpoint(\n",
    "    \"../deep_traffic_generation/lightning_logs/tcvae/version_1/\" + \"checkpoints/\" + filenames2[0],\n",
    "    dataset_params=dataset2.parameters,\n",
    ")\n",
    "VAE2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We selected pairs of trajectories from traffic1 and traffic2\n",
    "\n",
    "- We make one dataset of takoffs for VAE1 and one dataset of landings for VAe2 based on the pairs (in one dataset, one trajectory may appear several times). Each input tensor is sorted according the pairs we identified.\n",
    "\n",
    "- We calculate the corresponding latent representations in VAE1 and VAE2 (we may take the means of each posterior or one randomly point). The output tensors are sorted according the pairs we identified.\n",
    "\n",
    "- We concatenate the two tensors and train the meta VAE. input: linear tensor of size(nb_pairs, 2, latent_dim) or size(nb_pairs, 2*latent_dim). Either we only do TCN VAE or Dense VAE.  \n",
    "\n",
    "- If everything works well: We are able to generate a new pair of latent representations with the meta VAE. Then we pass each representation in the corresponding VAE to get the reconstructed trajectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = VAE1.encoder(a)\n",
    "q1 = VAE1.lsr(h1)\n",
    "z1 = q1.rsample()\n",
    "\n",
    "h2 = VAE2.encoder(b)\n",
    "q2 = VAE2.lsr(h2)\n",
    "z2 = q2.rsample()\n",
    "\n",
    "#linear\n",
    "lin = torch.cat((z1, z2), axis = 1)\n",
    "\n",
    "#sequence\n",
    "seq = torch.cat((z1.unsqueeze(-1), z2.unsqueeze(-1)), axis = 2)\n",
    "\n",
    "#image\n",
    "img = torch.cat((z1.unsqueeze(-1), z2.unsqueeze(-1)), axis = 2).transpose(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for MetaDatasetPairs class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_traffic_generation.core.datasets import TrafficDataset, MetaDatasetPairs\n",
    "from deep_traffic_generation.tcvae import TCVAE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): TCN(\n",
       "      (network): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (tmp_block1): TemporalBlock(\n",
       "            (conv): Conv1d(4, 64, kernel_size=(16,), stride=(1,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (tmp_block2): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (downsample): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (tmp_block1): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (tmp_block2): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (tmp_block1): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "            (out_activ): ReLU()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (tmp_block2): TemporalBlock(\n",
       "            (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AvgPool1d(kernel_size=(10,), stride=(10,), padding=(0,))\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (lsr): VampPriorLSR(\n",
       "    (encoder): Sequential(\n",
       "      (0): TCN(\n",
       "        (network): Sequential(\n",
       "          (0): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(4, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (downsample): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (1): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): AvgPool1d(kernel_size=(10,), stride=(10,), padding=(0,))\n",
       "      (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (z_loc): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=True)\n",
       "    )\n",
       "    (z_log_var): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=True)\n",
       "      (1): Hardtanh(min_val=-6.0, max_val=6.0)\n",
       "    )\n",
       "    (pseudo_inputs_NN): Sequential(\n",
       "      (0): Linear(in_features=800, out_features=800, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=800, out_features=800, bias=True)\n",
       "      (3): Hardtanh(min_val=-1.0, max_val=1.0)\n",
       "    )\n",
       "    (prior_log_var_NN): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=64, bias=True)\n",
       "      (1): Hardtanh(min_val=-6.0, max_val=6.0)\n",
       "    )\n",
       "  )\n",
       "  (decoder): TCDecoder(\n",
       "    (decode_entry): Linear(in_features=64, out_features=1280, bias=True)\n",
       "    (decoder): Sequential(\n",
       "      (0): Upsample(scale_factor=10.0, mode=nearest)\n",
       "      (1): TCN(\n",
       "        (network): Sequential(\n",
       "          (0): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(64, 64, kernel_size=(16,), stride=(1,), dilation=(2,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualBlock(\n",
       "            (tmp_block1): TemporalBlock(\n",
       "              (conv): Conv1d(64, 4, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (out_activ): ReLU()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (tmp_block2): TemporalBlock(\n",
       "              (conv): Conv1d(4, 4, kernel_size=(16,), stride=(1,), dilation=(4,))\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (downsample): Conv1d(64, 4, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_activ): Identity()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = TrafficDataset.from_file(\n",
    "    (\"../deep_traffic_generation/data/training_datasets/takeoffs_south_LFPO_07.pkl\"),\n",
    "    features=[\"track\", \"groundspeed\", \"altitude\", \"timedelta\"],\n",
    "    scaler=MinMaxScaler(feature_range=(-1,1)),\n",
    "    # scaler=None,\n",
    "    shape=\"image\",\n",
    "    info_params={\"features\": [\"latitude\", \"longitude\"], \"index\": -1},\n",
    ")\n",
    "\n",
    "dataset2 = TrafficDataset.from_file(\n",
    "    (\"../deep_traffic_generation/data/training_datasets/landings_south_LFPO_06.pkl\"),\n",
    "    features=[\"track\", \"groundspeed\", \"altitude\", \"timedelta\"],\n",
    "    scaler=MinMaxScaler(feature_range=(-1,1)),\n",
    "    # scaler=None,\n",
    "    shape=\"image\",\n",
    "    info_params={\"features\": [\"latitude\", \"longitude\"], \"index\": -1},\n",
    ")\n",
    "\n",
    "file_path1 = \"../deep_traffic_generation/data/training_datasets/takeoffs_south_LFPO_07.pkl\"\n",
    "file_path2 = \"../deep_traffic_generation/data/training_datasets/landings_south_LFPO_06.pkl\"\n",
    "\n",
    "filenames1 = next(walk(\"../deep_traffic_generation/lightning_logs/tcvae/version_0/\"+ \"checkpoints/\"), (None, None, []))[2]\n",
    "VAE1 = TCVAE.load_from_checkpoint(\n",
    "    \"../deep_traffic_generation/lightning_logs/tcvae/version_0/\" + \"checkpoints/\" + filenames1[0],\n",
    "    dataset_params=dataset1.parameters,\n",
    ")\n",
    "VAE1.eval()\n",
    "\n",
    "filenames2 = next(walk(\"../deep_traffic_generation/lightning_logs/tcvae/version_1/\"+ \"checkpoints/\"), (None, None, []))[2]\n",
    "VAE2 = TCVAE.load_from_checkpoint(\n",
    "    \"../deep_traffic_generation/lightning_logs/tcvae/version_1/\" + \"checkpoints/\" + filenames2[0],\n",
    "    dataset_params=dataset2.parameters,\n",
    ")\n",
    "VAE2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset = MetaDatasetPairs.create_dataset((file_path1, file_path2), \n",
    "                                               dataset1, \n",
    "                                               dataset2, \n",
    "                                               VAE1,\n",
    "                                               VAE2, \n",
    "                                               shape= \"image\",\n",
    "                                               scaler=MinMaxScaler(feature_range=(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pairs_generation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28a3cd3f5cb72c6a943a2ac4ce0cce03fe93216c6813c76b2962abe15657ea5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
